# Starocks

- [starocks存储区块链数据](./starocks_chain.md)

## **StarRocks 物化视图增量更新：是否基于时间？**

StarRocks 的 **物化视图增量更新** **不完全基于时间**，而是通过 **基于 Base + Delta 的增量计算** 进行刷新。它并不是简单按照时间字段（如 `timestamp`）进行更新，而是利用数据的变更（Insert / Update / Delete）来计算增量。  

---

## **1. StarRocks 物化视图增量更新机制**
StarRocks 的增量更新依赖于 **两部分数据**：
1. **Base（已有的数据）**：物化视图构建时的初始数据快照。
2. **Delta（增量数据）**：自上次刷新后，新写入或修改的部分。

### 📌 **关键点**
- **增量计算是基于数据变更，而不是基于时间字段**。
- **支持 INSERT、UPDATE、DELETE 类型的变更**，并根据不同的物化视图模型自动合并数据。  
- **自动增量更新（`REFRESH AUTO`）根据数据量大小和导入方式决定触发机制**，但仍会有一定的**时间延迟（秒级）**。

---

## **2. 增量更新的触发条件**
StarRocks 物化视图的增量刷新基于 **数据变更**，触发方式如下：
- **自动增量刷新（REFRESH AUTO）**
  - 当 StarRocks 检测到基础表数据变更后，会**周期性**地进行增量计算并刷新 MV。
  - 刷新间隔由系统内部调度决定，通常在 **秒级**，但不是严格的**实时更新**。
  - 适用于 **高频更新的数据流，如 Kafka Stream Load**。
  
- **手动刷新（REFRESH MANUAL）**
  - 需要用户**手动执行 `REFRESH MATERIALIZED VIEW`** 命令进行增量计算和更新。
  - 适用于 **离线批量计算、数据更新不频繁的场景**。

---

## StarRocks和ClickHouse 物化视图对比

| **对比项**   | **StarRocks 物化视图**    | **ClickHouse 物化视图**       |
| ------------ | ------------------------- | ----------------------------- |
| **更新方式** | 增量刷新（可手动/自动）   | 仅支持手动（`REFRESH`）       |
| **查询优化** | 自动命中（Query Rewrite） | 依赖 `POPULATE`（不自动刷新） |
| **更新触发** | 自动 / 手动               | 手动（批量更新）              |
| **实时性**   | 近实时（秒级）            | 较慢（批处理）                |
| **适用场景** | 高并发查询，准实时聚合    | 历史数据 OLAP 聚合            |


---

## **1. StarRocks vs. ClickHouse 对比**

| **对比项**    | **StarRocks**                                        | **ClickHouse**                                |
| ------------- | ---------------------------------------------------- | --------------------------------------------- |
| **数据模型**  | **MPP（多节点分布式）+ 向量化执行**                  | **列式存储 + 向量化执行**                     |
| **数据写入**  | **支持高并发批量 & 流式导入**（Kafka / Stream Load） | **批量导入性能高，但流式导入较弱**            |
| **查询性能**  | **自动索引 + 物化视图优化查询**（Query Rewrite）     | **依赖手动创建索引 & 物化视图**（`POPULATE`） |
| **实时性**    | **近实时（秒级延迟）**                               | **准实时（分钟级）**                          |
| **主键支持**  | **支持更新（Primary Key 模型），适合账户余额等数据** | **写入后不可变更，需手动合并数据**            |
| **JOIN 计算** | **支持高效分布式 JOIN**，适合多表分析                | **JOIN 性能较弱**，不适合复杂关系查询         |
| **扩展性**    | **云原生架构，自动分区 & 动态扩展**                  | **手动分片，扩展较复杂**                      |
| **适用场景**  | **高并发 OLAP 查询，交易分析，账户数据更新**         | **大规模日志分析，区块链全历史数据归档**      |

---

## **2. 适用场景分析**
✅ **StarRocks 更适合：**
- **交易分析 & 账户余额计算**（高并发查询 + 低延迟更新）
- **链上 DeFi & NFT 数据分析**（多维度交互查询）
- **实时区块 & 交易监控**（Kafka 实时流数据）

✅ **ClickHouse 更适合：**
- **链上全量历史数据存储 & 批量查询**（一次性分析大数据集）
- **区块链日志分析**（合约日志 / 节点日志）
- **长期归档 & 批处理分析**（低频查询但数据量大）

---

## StarRocks离线计算
- 🔹 StarRocks 可以直接导入离线计算，并支持多种方式，如 OUTFILE、Spark Connector、Flink 等。
- 🔹 最推荐的方式是 Spark / Flink 直接读取 StarRocks，避免额外的数据导出，提高效率。
- 🔹 可以结合 StarRocks 物化视图进行预计算，减少离线计算负担，提高查询性能。 🚀

# **StarRocks 的 Query Rewrite（查询改写）**  

**Query Rewrite（查询改写）** 是 StarRocks 提供的一种 **自动优化查询** 的机制，主要用于 **自动命中物化视图**，减少计算量，提高查询性能。  

---

## **🔹 Query Rewrite 的工作原理**
1. **创建物化视图（Materialized View, MV）**  
   - 用户预计算 & 存储部分查询结果，提高查询效率。
2. **执行查询时，StarRocks 自动匹配物化视图**  
   - **查询改写（Query Rewrite）机制** 会自动 **重写 SQL 语句**，让查询直接从物化视图中获取数据，而不是扫描原始大表。
3. **用户无需手动指定物化视图**  
   - StarRocks 会**智能判断**是否可以使用物化视图，并自动改写 SQL，以加速查询。

---


## **ClickHouse vs. StarRocks 适用场景对比**

| **对比项**       | **ClickHouse**                                    | **StarRocks**                                           |
| ---------------- | ------------------------------------------------- | ------------------------------------------------------- |
| **数据更新方式** | 追加写入 (`MergeTree`)，支持 `ReplacingMergeTree` | `DUPLICATE KEY`（支持更新）或 `PRIMARY KEY`（实时更新） |
| **查询优化**     | 适用于批量分析，高效 `ORDER BY` & `bloom_filter`  | `Query Rewrite` + 物化视图优化                          |
| **实时性**       | 主要适用于批处理                                  | 近实时数据分析                                          |
| **适用场景**     | 历史交易分析、大规模批量数据存储                  | 高并发查询、实时数据分析                                |


# ClickHouse vs. StarRocks 数据均衡对比

| **对比项**       | **ClickHouse**                | **StarRocks**        |
| ---------------- | ----------------------------- | -------------------- |
| **自动数据均衡** | ❌ 不支持（需手动迁移）        | ✅ 自动均衡数据       |
| **新节点拓展**   | 需要手动迁移旧数据            | 自动平衡存储 & 计算  |
| **负载均衡**     | 通过 `Distributed` 表均衡查询 | 内部自动均衡数据分布 |

## kafka数据导入starocks
| 方法                  | 适用场景       | 优势                     | 适用数据格式        |
| --------------------- | -------------- | ------------------------ | ------------------- |
| **Routine Load**      | 长期持续导入   | 自动化流式导入，稳定可靠 | JSON、CSV           |
| **Flink + StarRocks** | 大规模数据同步 | 可实时处理 ETL 逻辑      | JSON、Avro、Parquet |
| **Stream Load**       | 小规模批量导入 | 支持 HTTP 接口           | JSON、CSV           |

### **推荐**
- **如果是实时消费 Kafka 数据** → **Routine Load**
- **如果需要数据清洗、转换** → **Flink + StarRocks**
- **如果是批量数据** → **Stream Load**

### 查询优化
StarRocks 中，索引的概念与传统数据库（如 MySQL、PostgreSQL）不同，它主要依靠 主键索引（Primary Key Index）、排序键（Sort Key） 和 前缀索引（Prefix Index） 来加速查询。StarRocks 通过 存储引擎优化和数据分布策略 来提高查询效率，而不支持显式的 CREATE INDEX 语法。


| 索引类型                     | 适用场景                                 | 查询优化                           | 示例                                                  |
| ---------------------------- | ---------------------------------------- | ---------------------------------- | ----------------------------------------------------- |
| **主键索引（Primary Key）**  | 交易唯一标识 (`tx_hash`)                 | `WHERE tx_hash = '0xabc...'`       | `PRIMARY KEY(tx_hash)`                                |
| **排序键（Sort Key）**       | 和联合索引差不多 时间排序 (`block_time`) | `ORDER BY block_time DESC`         | `DUPLICATE KEY(from_address, to_address, block_time)` |
| **前缀索引（Prefix Index）** | 地址前缀匹配 (`0xabc%`)                  | `WHERE from_address LIKE '0xabc%'` | `BITMAP INDEX (from_address)`                         |

### 部署
共4台，每台10T存储
- FE节点：3台，保证元数据高可用。
- BE节点：4台，每台存储5TB数据，总20TB满足双副本需求。
- Broker节点：2台，可以与其他节点共用。


