## 数据处理

[数据挖掘OneHotEncoder独热编码和LabelEncoder标签编码](https://blog.csdn.net/ccblogger/article/details/80010974)

#### 使用sklearn生成样本

[sklearn样本生成](https://blog.csdn.net/hqh131360239/article/details/79170259)

- n_samples:待生成样本的总数
- n_features:每个样本的特征数
- centers:(聚类)表示类别数
- cluster_std:(聚类)每个类别的方差,我们希望生成2类数据，其中一类比另一类具有更大的方差，可以将cluster_std设置为[1.0,3.0]
- n_informative:多信息特征的个数
- n_redundant:冗余信息,informative特征的随机线性组合
- n_repeated:重复信息，随机提取n_informative和n_redundant 特征
- n_classes:分类类别
- n_clusters_per_class:某一个类别是由几个cluster构成的
- random_state:随机因子

### 数据预处理

#### 归一化标准化
[preprocessing](httpspreprocessing://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)
- 标准化(StandardScaler):将数据缩放到均值为0,方差为1
    - 受异常值影响小
- 归一化(Normalization,MinMaxScaler):将数据缩放到[0,1]
    - 缺陷在于如果样本中存在极大或者极小的异常值，这样归一化的结果往往准确性较低

##### 归一化标准化的好处
- 模型收敛快
- 加快训练速度
- 减少量纲差别,带来的准确性bbb

##### 独热编码和归一化
- 独热编码:
    - 用:离散数据
    - 不用:类别太多,树模型(增加树的深度)
- 归一化:
    - 用: 基于参数的模型或基于距离的模型，都是要进行特征的归一化
    - 不用: 基于树的方法是不需要进行特征的归一化，例如随机森林，bagging 和 boosting等

#### 缺失值的处理
```python

import numpy as np
import pandas as pd
from sklearn.impute import SimpleImputer

dataset = pd.read_csv('./data/1.csv')
columns = ['Age','Salary']

imputer = SimpleImputer(missing_values=np.nan,strategy="mean")
datasetna = imputer.fit_transform(dataset[columns].values)
dataset[columns] = datasetna
dataset
```



